basline (trained, "baseline"): submitted
bidaf   (trained, "bidaf")
bidaf + smart get_start(K=15) : submitted // {"f1": 52.350024821759746, "exact_match": 44.19753086419753} (improvements1+2)
stacked bidaf (n=3) (trained, "stacked") // {"f1": 50.036426171559775, "exact_match": 43.08641975308642} (FIS)
added DrQA features (num_feats=4), smart get_start(K=15), one-layer RNN (trained, "feat") // {"f1": 65.48; "exact_match": 56.54} (HWG HWG)
added aligned question embedding, SEPARATE ENCODERS, smart get_start(K=15), one-layer RNN  (trained, "aligned")
aligned question embedding, SHARED ENCODERS, smart get_start(K=15), one-layer RNN (trained, "aligned_share") -- loss curve looks identical to separate encoders

other things:
- keep word embeddings fixed, except for 1000 most common question words